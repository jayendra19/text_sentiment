{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jayen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jayen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\jayen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import spacy\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Download NLTK resources (do it once)\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>According to Gran , the company has no plans t...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Technopolis plans to develop in stages an area...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>The international electronic industry company ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>With the new production plant the company woul...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>According to the company 's updated strategy f...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512672</th>\n",
       "      <td>531249</td>\n",
       "      <td>Man, I loved this movie! This really takes me ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512673</th>\n",
       "      <td>531250</td>\n",
       "      <td>Recovery is an incredibly moving piece of work...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512674</th>\n",
       "      <td>531251</td>\n",
       "      <td>You can take the crook out of the joint, but i...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512675</th>\n",
       "      <td>531252</td>\n",
       "      <td>FUTZ is the only show preserved from the exper...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512676</th>\n",
       "      <td>531253</td>\n",
       "      <td>\"The Mother\" tells of a recently widowed mid-6...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>512677 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                               text  \\\n",
       "0                0  According to Gran , the company has no plans t...   \n",
       "1                1  Technopolis plans to develop in stages an area...   \n",
       "2                2  The international electronic industry company ...   \n",
       "3                3  With the new production plant the company woul...   \n",
       "4                4  According to the company 's updated strategy f...   \n",
       "...            ...                                                ...   \n",
       "512672      531249  Man, I loved this movie! This really takes me ...   \n",
       "512673      531250  Recovery is an incredibly moving piece of work...   \n",
       "512674      531251  You can take the crook out of the joint, but i...   \n",
       "512675      531252  FUTZ is the only show preserved from the exper...   \n",
       "512676      531253  \"The Mother\" tells of a recently widowed mid-6...   \n",
       "\n",
       "           label  \n",
       "0        neutral  \n",
       "1        neutral  \n",
       "2       negative  \n",
       "3       positive  \n",
       "4       positive  \n",
       "...          ...  \n",
       "512672  positive  \n",
       "512673  positive  \n",
       "512674  positive  \n",
       "512675  positive  \n",
       "512676  positive  \n",
       "\n",
       "[512677 rows x 3 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file=r\"C:\\Users\\jayen\\Text-sentiment-analysis-general-purpose\\artifacts\\Forsentiment2.csv\"\n",
    "#n=100000\n",
    "df=pd.read_csv(file)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 531254 entries, 0 to 531253\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    512684 non-null  object\n",
      " 1   label   512800 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 8.1+ MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_label_mapping = {'neutral': 0, 'positive': 1, 'negative': 2}\n",
    "# Map class names to numerical labels\n",
    "df['label'] = df['label'].replace(class_label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=LabelEncoder()\n",
    "df['labels']=l.fit_transform(df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>According to Gran , the company has no plans t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Technopolis plans to develop in stages an area...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>The international electronic industry company ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>With the new production plant the company woul...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>According to the company 's updated strategy f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512672</th>\n",
       "      <td>531249</td>\n",
       "      <td>Man, I loved this movie! This really takes me ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512673</th>\n",
       "      <td>531250</td>\n",
       "      <td>Recovery is an incredibly moving piece of work...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512674</th>\n",
       "      <td>531251</td>\n",
       "      <td>You can take the crook out of the joint, but i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512675</th>\n",
       "      <td>531252</td>\n",
       "      <td>FUTZ is the only show preserved from the exper...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512676</th>\n",
       "      <td>531253</td>\n",
       "      <td>\"The Mother\" tells of a recently widowed mid-6...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>512677 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                               text  label\n",
       "0                0  According to Gran , the company has no plans t...      0\n",
       "1                1  Technopolis plans to develop in stages an area...      0\n",
       "2                2  The international electronic industry company ...      2\n",
       "3                3  With the new production plant the company woul...      1\n",
       "4                4  According to the company 's updated strategy f...      1\n",
       "...            ...                                                ...    ...\n",
       "512672      531249  Man, I loved this movie! This really takes me ...      1\n",
       "512673      531250  Recovery is an incredibly moving piece of work...      1\n",
       "512674      531251  You can take the crook out of the joint, but i...      1\n",
       "512675      531252  FUTZ is the only show preserved from the exper...      1\n",
       "512676      531253  \"The Mother\" tells of a recently widowed mid-6...      1\n",
       "\n",
       "[512677 rows x 3 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>According to Gran , the company has no plans t...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Technopolis plans to develop in stages an area...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>The international electronic industry company ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>With the new production plant the company woul...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>According to the company 's updated strategy f...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512672</th>\n",
       "      <td>531249</td>\n",
       "      <td>Man, I loved this movie! This really takes me ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512673</th>\n",
       "      <td>531250</td>\n",
       "      <td>Recovery is an incredibly moving piece of work...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512674</th>\n",
       "      <td>531251</td>\n",
       "      <td>You can take the crook out of the joint, but i...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512675</th>\n",
       "      <td>531252</td>\n",
       "      <td>FUTZ is the only show preserved from the exper...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512676</th>\n",
       "      <td>531253</td>\n",
       "      <td>\"The Mother\" tells of a recently widowed mid-6...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>512677 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                               text  \\\n",
       "0                0  According to Gran , the company has no plans t...   \n",
       "1                1  Technopolis plans to develop in stages an area...   \n",
       "2                2  The international electronic industry company ...   \n",
       "3                3  With the new production plant the company woul...   \n",
       "4                4  According to the company 's updated strategy f...   \n",
       "...            ...                                                ...   \n",
       "512672      531249  Man, I loved this movie! This really takes me ...   \n",
       "512673      531250  Recovery is an incredibly moving piece of work...   \n",
       "512674      531251  You can take the crook out of the joint, but i...   \n",
       "512675      531252  FUTZ is the only show preserved from the exper...   \n",
       "512676      531253  \"The Mother\" tells of a recently widowed mid-6...   \n",
       "\n",
       "           label  \n",
       "0        neutral  \n",
       "1        neutral  \n",
       "2       negative  \n",
       "3       positive  \n",
       "4       positive  \n",
       "...          ...  \n",
       "512672  positive  \n",
       "512673  positive  \n",
       "512674  positive  \n",
       "512675  positive  \n",
       "512676  positive  \n",
       "\n",
       "[512677 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label']=df['label'].replace('normal','neutral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    323305\n",
       "2    103495\n",
       "0     85877\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    0\n",
       "text          0\n",
       "label         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#there are some missing values in label and in text too\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "positive    323305\n",
       "negative    103495\n",
       "neutral      85877\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'C:\\Users\\jayen\\Text-sentiment-analysis-general-purpose\\artifacts\\Forsentiment3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOW ILL DO SOME PREPROCESSING STEPS FOR THAT ILL CREATE A FUNCTION\n",
    "def preprocessing(q):\n",
    " \n",
    "  q=str(q).lower().strip()#strip gives a string in return if u use split it will give a list of words\n",
    "  #The strip() method in Python is used to remove leading and trailing characters (whitespace characters by default) from a string before \" Hello, world! \" after\"Hello, world!\"\n",
    "   # Replace certain special characters with their string equivalents\n",
    "  q = q.replace('%', 'percent')\n",
    "  q = q.replace('$', 'dollar ')\n",
    "  q = q.replace('â‚¹', 'rupee ')\n",
    "  q = q.replace('â‚¬', 'euro ')\n",
    "  q = q.replace('@', 'at')\n",
    "  q=q.replace('&','and')\n",
    "\n",
    "  q = re.sub(r'([0-9]+)000000000', r'\\1b', re.sub(r'([0-9]+)000000', r'\\1m', re.sub(r'([0-9]+)000', r'\\1k', q)))#Input: \"1500000000 Output: \"1.5b\" it will do this \n",
    "\n",
    "\n",
    "\n",
    "    # https://en.wikipedia.org/wiki/Wikipedia%3aList_of_English_contractions\n",
    "    # https://stackoverflow.com/a/19794953\n",
    "  contractions = {\n",
    "    \"ain't\": \"am not\",\n",
    "    \"aren't\": \"are not\",\n",
    "    \"can't\": \"can not\",\n",
    "    \"can't've\": \"can not have\",\n",
    "    \"'cause\": \"because\",\n",
    "    \"could've\": \"could have\",\n",
    "    \"couldn't\": \"could not\",\n",
    "    \"couldn't've\": \"could not have\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"hadn't've\": \"had not have\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"he'd\": \"he would\",\n",
    "    \"he'd've\": \"he would have\",\n",
    "    \"he'll\": \"he will\",\n",
    "    \"he'll've\": \"he will have\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"how'd\": \"how did\",\n",
    "    \"how'd'y\": \"how do you\",\n",
    "    \"how'll\": \"how will\",\n",
    "    \"how's\": \"how is\",\n",
    "    \"i'd\": \"i would\",\n",
    "    \"i'd've\": \"i would have\",\n",
    "    \"i'll\": \"i will\",\n",
    "    \"i'll've\": \"i will have\",\n",
    "    \"i'm\": \"i am\",\n",
    "    \"i've\": \"i have\",\n",
    "    \"isn't\": \"is not\",\n",
    "    \"it'd\": \"it would\",\n",
    "    \"it'd've\": \"it would have\",\n",
    "    \"it'll\": \"it will\",\n",
    "    \"it'll've\": \"it will have\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"let's\": \"let us\",\n",
    "    \"ma'am\": \"madam\",\n",
    "    \"mayn't\": \"may not\",\n",
    "    \"might've\": \"might have\",\n",
    "    \"mightn't\": \"might not\",\n",
    "    \"mightn't've\": \"might not have\",\n",
    "    \"must've\": \"must have\",\n",
    "    \"mustn't\": \"must not\",\n",
    "    \"mustn't've\": \"must not have\",\n",
    "    \"needn't\": \"need not\",\n",
    "    \"needn't've\": \"need not have\",\n",
    "    \"o'clock\": \"of the clock\",\n",
    "    \"oughtn't\": \"ought not\",\n",
    "    \"oughtn't've\": \"ought not have\",\n",
    "    \"shan't\": \"shall not\",\n",
    "    \"sha'n't\": \"shall not\",\n",
    "    \"shan't've\": \"shall not have\",\n",
    "    \"she'd\": \"she would\",\n",
    "    \"she'd've\": \"she would have\",\n",
    "    \"she'll\": \"she will\",\n",
    "    \"she'll've\": \"she will have\",\n",
    "    \"she's\": \"she is\",\n",
    "    \"should've\": \"should have\",\n",
    "    \"shouldn't\": \"should not\",\n",
    "    \"shouldn't've\": \"should not have\",\n",
    "    \"so've\": \"so have\",\n",
    "    \"so's\": \"so as\",\n",
    "    \"that'd\": \"that would\",\n",
    "    \"that'd've\": \"that would have\",\n",
    "    \"that's\": \"that is\",\n",
    "    \"there'd\": \"there would\",\n",
    "    \"there'd've\": \"there would have\",\n",
    "    \"there's\": \"there is\",\n",
    "    \"they'd\": \"they would\",\n",
    "    \"they'd've\": \"they would have\",\n",
    "    \"they'll\": \"they will\",\n",
    "    \"they'll've\": \"they will have\",\n",
    "    \"they're\": \"they are\",\n",
    "    \"they've\": \"they have\",\n",
    "    \"to've\": \"to have\",\n",
    "    \"wasn't\": \"was not\",\n",
    "    \"we'd\": \"we would\",\n",
    "    \"we'd've\": \"we would have\",\n",
    "    \"we'll\": \"we will\",\n",
    "    \"we'll've\": \"we will have\",\n",
    "    \"we're\": \"we are\",\n",
    "    \"we've\": \"we have\",\n",
    "    \"weren't\": \"were not\",\n",
    "    \"what'll\": \"what will\",\n",
    "    \"what'll've\": \"what will have\",\n",
    "    \"what're\": \"what are\",\n",
    "    \"what's\": \"what is\",\n",
    "    \"what've\": \"what have\",\n",
    "    \"when's\": \"when is\",\n",
    "    \"when've\": \"when have\",\n",
    "    \"where'd\": \"where did\",\n",
    "    \"where's\": \"where is\",\n",
    "    \"where've\": \"where have\",\n",
    "    \"who'll\": \"who will\",\n",
    "    \"who'll've\": \"who will have\",\n",
    "    \"who's\": \"who is\",\n",
    "    \"who've\": \"who have\",\n",
    "    \"why's\": \"why is\",\n",
    "    \"why've\": \"why have\",\n",
    "    \"will've\": \"will have\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"won't've\": \"will not have\",\n",
    "    \"would've\": \"would have\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"wouldn't've\": \"would not have\",\n",
    "    \"y'all\": \"you all\",\n",
    "    \"y'all'd\": \"you all would\",\n",
    "    \"y'all'd've\": \"you all would have\",\n",
    "    \"y'all're\": \"you all are\",\n",
    "    \"y'all've\": \"you all have\",\n",
    "    \"you'd\": \"you would\",\n",
    "    \"you'd've\": \"you would have\",\n",
    "    \"you'll\": \"you will\",\n",
    "    \"you'll've\": \"you will have\",\n",
    "    \"you're\": \"you are\",\n",
    "    \"you've\": \"you have\"\n",
    "    }\n",
    "  q_decontracted=[]\n",
    "\n",
    "  q_decontracted = [contractions[i] if i in contractions else i for i in q.split()]\n",
    "\n",
    "\n",
    "  #now i join this word into q\n",
    "  q=' '.join(q_decontracted)\n",
    "  q = q.replace(\"'ve\", \" have\")\n",
    "  q = q.replace(\"n't\", \" not\")\n",
    "  q = q.replace(\"'re\", \" are\")\n",
    "  q = q.replace(\"'ll\", \" will\")\n",
    "  # Removing HTML tags\n",
    "  q = BeautifulSoup(q)\n",
    "  q = q.get_text()\n",
    "  # Remove punctuations like ,.\"\"[]\n",
    "  q =re.sub(r'[^\\w\\s{}\\/<>\\'\"\\-_=+()*~:;]', ' ', q)\n",
    "\n",
    "  q = word_tokenize(q)  # Convert to lowercase\n",
    "\n",
    "  # Remove stopwords and non-alphabetic characters, perform lemmatization\n",
    "  q = [\n",
    "        lemmatizer.lemmatize(word) for word in q\n",
    "        if word not in stop_words\n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "  return ' '.join(q)#ALWAYS REMEMBER IN ORDER TO USE WORD2VEC UR SENTENSES SHOULD BE IN TOKKENS OR WORDS BUT IN THIS CASE WE HAVE TO TRAIN OUR MODEL WE HAVE TO TOOKENIZE\n",
    "  #THE WORDS SO WE USE JOIN THEN AFTER WE TOKKENIZE IT WONT BE ABLE TO CONCATINATE LIST OF STRINGS IMPORTANT. contain lists instead of strings.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jayen\\AppData\\Local\\Temp\\ipykernel_5600\\495576266.py:151: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  q = BeautifulSoup(q)\n"
     ]
    }
   ],
   "source": [
    "df['preprocessed']=df['text'].apply(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['finnish', 'Okmetic', 'manufacture', 'process', 'silicon', 'wafer', 'semiconductor', 'sensor', 'industry', 'norwegian', 'solar', 'wafer', 'company', 'NorSun', 'sign', 'contract', 'Okmetic', 'supply', 'NorSun', 'mono', 'silicon', 'crystal', 'use', 'solar', 'cell', 'manufacturing', '.,positive']\n"
     ]
    }
   ],
   "source": [
    "#TRIED THE SPACY MODEL BUT ITS TAKING MORE TIME TO PROCEES EACH SENETENSES FOR PREPROCESSING ALWAYS USE NLTK  U CAN SEE THE RUNTIME\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Finnish Okmetic that manufactures and processes silicon wafers for the semiconductor and sensor industries and Norwegian solar wafer company NorSun have signed a contract under which Okmetic will supply NorSun mono silicon crystals for use in solar cell manufacturing .,positive\"\n",
    "\n",
    ")\n",
    "\n",
    "  # Remove stop words and perform lemmatization\n",
    "a = [token.lemma_ for token in doc if not token.is_stop]\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jayen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jayen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\jayen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Finnish', 'real', 'estate', 'investor', 'Sponda', 'Plc', 'said', 'Wednesday', '12', 'March', 'signed', 'agreement', 'Danske', 'Bank', 'A-S', ',', 'Helsinki', 'Branch', '7-year', 'EUR150m', 'credit', 'facility', 'Ilmarinen', 'Mutual', 'Pension', 'Insurance', 'Company', '7-year', 'EUR50m', 'credit', 'facility', '.']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "# Download NLTK resources (do it once)\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Finnish', 'Okmetic', 'manufacture', 'process', 'silicon', 'wafer', 'semiconductor', 'sensor', 'industry', 'Norwegian', 'solar', 'wafer', 'company', 'NorSun', 'signed', 'contract', 'Okmetic', 'supply', 'NorSun', 'mono', 'silicon', 'crystal', 'use', 'solar', 'cell', 'manufacturing', '.', ',', 'positive']\n"
     ]
    }
   ],
   "source": [
    "q = word_tokenize(\"Finnish Okmetic that manufactures and processes silicon wafers for the semiconductor and sensor industries and Norwegian solar wafer company NorSun have signed a contract under which Okmetic will supply NorSun mono silicon crystals for use in solar cell manufacturing .,positive\")  # Convert to lowercase\n",
    "\n",
    "# Remove stopwords and non-alphabetic characters, perform lemmatization\n",
    "q = [\n",
    "    lemmatizer.lemmatize(word) for word in q\n",
    "    if word not in stop_words\n",
    "]\n",
    "\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>According to Gran , the company has no plans t...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>according gran company plan move production ru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Technopolis plans to develop in stages an area...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>technopolis plan develop stage area le 100 000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The international electronic industry company ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>international electronic industry company elco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>With the new production plant the company woul...</td>\n",
       "      <td>positive</td>\n",
       "      <td>new production plant company would increase ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>According to the company 's updated strategy f...</td>\n",
       "      <td>positive</td>\n",
       "      <td>according company 's updated strategy year 200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531249</th>\n",
       "      <td>Man, I loved this movie! This really takes me ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>man loved movie really take back kid day teach...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531250</th>\n",
       "      <td>Recovery is an incredibly moving piece of work...</td>\n",
       "      <td>positive</td>\n",
       "      <td>recovery incredibly moving piece work handling...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531251</th>\n",
       "      <td>You can take the crook out of the joint, but i...</td>\n",
       "      <td>positive</td>\n",
       "      <td>take crook joint seems exceedingly difficult t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531252</th>\n",
       "      <td>FUTZ is the only show preserved from the exper...</td>\n",
       "      <td>positive</td>\n",
       "      <td>futz show preserved experimental theatre movem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531253</th>\n",
       "      <td>\"The Mother\" tells of a recently widowed mid-6...</td>\n",
       "      <td>positive</td>\n",
       "      <td>`` mother '' tell recently widowed mid-60 's m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>512677 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text     label  \\\n",
       "0       According to Gran , the company has no plans t...   neutral   \n",
       "1       Technopolis plans to develop in stages an area...   neutral   \n",
       "2       The international electronic industry company ...  negative   \n",
       "3       With the new production plant the company woul...  positive   \n",
       "4       According to the company 's updated strategy f...  positive   \n",
       "...                                                   ...       ...   \n",
       "531249  Man, I loved this movie! This really takes me ...  positive   \n",
       "531250  Recovery is an incredibly moving piece of work...  positive   \n",
       "531251  You can take the crook out of the joint, but i...  positive   \n",
       "531252  FUTZ is the only show preserved from the exper...  positive   \n",
       "531253  \"The Mother\" tells of a recently widowed mid-6...  positive   \n",
       "\n",
       "                                             preprocessed  \n",
       "0       according gran company plan move production ru...  \n",
       "1       technopolis plan develop stage area le 100 000...  \n",
       "2       international electronic industry company elco...  \n",
       "3       new production plant company would increase ca...  \n",
       "4       according company 's updated strategy year 200...  \n",
       "...                                                   ...  \n",
       "531249  man loved movie really take back kid day teach...  \n",
       "531250  recovery incredibly moving piece work handling...  \n",
       "531251  take crook joint seems exceedingly difficult t...  \n",
       "531252  futz show preserved experimental theatre movem...  \n",
       "531253  `` mother '' tell recently widowed mid-60 's m...  \n",
       "\n",
       "[512677 rows x 3 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df['preprocessed'])\n",
    "sequences = tokenizer.texts_to_sequences(df['preprocessed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 200  # Define your maximum sequence length\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_length)#THIS WILL BE MY ACTUAL DATA THAT'LL TRAIN TEST AND SPLIT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,   574, 22156,   161,   628,   493,   439,  1907,   331,\n",
       "         161,  1640])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index#THESE ARE MY UNIQUE WORDS WITH ITS UNIQUE INDEX\n",
    "print(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = len(word_index)+1#THIS WILL GET THE TOTAL NUMBER OF UNIQUE WORDS LENTTH MEANS VOCABULARY "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 200, 300)          9235800   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200, 300)          0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 100)               160400    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 303       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9396503 (35.84 MB)\n",
      "Trainable params: 9396503 (35.84 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "## Creating model\n",
    "from tensorflow.keras.layers import Dropout\n",
    "embedding_vector_features=300 ##features representation each word wil get convert into a vector of 300\n",
    "model=Sequential()\n",
    "model.add(Embedding(num_words,embedding_vector_features,input_length=max_length))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(3,activation='softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_label_mapping = {'neutral': 0, 'positive': 1, 'negative': 2}\n",
    "# Map class names to numerical labels\n",
    "df['label'] = df['label'].replace(class_label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    61693\n",
       "2    10605\n",
       "0     9285\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_final=np.array(padded_sequences)\n",
    "y_final=np.array(df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,   888, 26080,   355,   632,   448,   396,  1856,   300,\n",
       "         355,  1528])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_final[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((281434, 200), (281434,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_final.shape,y_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='accuracy', patience=3, mode='max', verbose=1, baseline=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2040/2040 [==============================] - 643s 312ms/step - loss: 0.3566 - accuracy: 0.8702 - val_loss: 0.2543 - val_accuracy: 0.9169\n",
      "Epoch 2/10\n",
      "2040/2040 [==============================] - 615s 302ms/step - loss: 0.2276 - accuracy: 0.9213 - val_loss: 0.2506 - val_accuracy: 0.9154\n",
      "Epoch 3/10\n",
      "2040/2040 [==============================] - 644s 316ms/step - loss: 0.1749 - accuracy: 0.9390 - val_loss: 0.2606 - val_accuracy: 0.9132\n",
      "Epoch 4/10\n",
      "2040/2040 [==============================] - 681s 334ms/step - loss: 0.1440 - accuracy: 0.9496 - val_loss: 0.2808 - val_accuracy: 0.9094\n",
      "Epoch 5/10\n",
      "2040/2040 [==============================] - 680s 333ms/step - loss: 0.1269 - accuracy: 0.9552 - val_loss: 0.2882 - val_accuracy: 0.9136\n",
      "Epoch 6/10\n",
      "2040/2040 [==============================] - 684s 335ms/step - loss: 0.1140 - accuracy: 0.9597 - val_loss: 0.2964 - val_accuracy: 0.9114\n",
      "Epoch 7/10\n",
      "2040/2040 [==============================] - 780s 382ms/step - loss: 0.1055 - accuracy: 0.9630 - val_loss: 0.2966 - val_accuracy: 0.9098\n",
      "Epoch 8/10\n",
      "2040/2040 [==============================] - 845s 414ms/step - loss: 0.0981 - accuracy: 0.9649 - val_loss: 0.3301 - val_accuracy: 0.9113\n",
      "Epoch 9/10\n",
      "2040/2040 [==============================] - 820s 402ms/step - loss: 0.0952 - accuracy: 0.9667 - val_loss: 0.3216 - val_accuracy: 0.9124\n",
      "Epoch 10/10\n",
      "2040/2040 [==============================] - 594s 291ms/step - loss: 0.0906 - accuracy: 0.9679 - val_loss: 0.3321 - val_accuracy: 0.9102\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1a1c2469910>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_final,y_final, epochs=10, batch_size=32, validation_split=0.2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: artifacts\\chat_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: artifacts\\chat_model\\assets\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "artifacts_folder = \"artifacts\"\n",
    "os.makedirs(artifacts_folder, exist_ok=True)\n",
    "# Save the trained model to the \"artifacts\" folder\n",
    "model_filename = os.path.join(artifacts_folder, 'chat_model')\n",
    "model.save(model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
